{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCCDE: A Decision-Based Ensemble Framework for Intrusion Detection in The Internet of Vehicles\n",
    "This is the code for the paper entitled \"**LCCDE: A Decision-Based Ensemble Framework for Intrusion Detection in The Internet of Vehicles**\" accepted in 2022 IEEE Global Communications Conference (GLOBECOM).  \n",
    "Authors: Li Yang (lyang339@uwo.ca), Abdallah Shami (Abdallah.Shami@uwo.ca), Gary Stevens, and Stephen de Rusett  \n",
    "Organization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University, Ontario, Canada; S2E Technologies, St. Jacobs, Ontario, Canada  \n",
    "\n",
    "If you find this repository useful in your research, please cite:  \n",
    "L. Yang, A. Shami, G. Stevens, and S. DeRusett, â€œLCCDE: A Decision-Based Ensemble Framework for Intrusion Detection in The Internet of Vehicles,\" in 2022 IEEE Global Communications Conference (GLOBECOM), 2022, pp. 1-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a67b236d781d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, precision_score, recall_score, f1_score\n",
    "import lightgbm as lgb\n",
    "import catboost as cbt\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from river import stream\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the sampled CICIDS2017 dataset\n",
    "The CICIDS2017 dataset is publicly available at: https://www.unb.ca/cic/datasets/ids-2017.html  \n",
    "Due to the large size of this dataset, the sampled subsets of CICIDS2017 is used. The subsets are in the \"data\" folder.  \n",
    "If you want to use this code on other datasets (e.g., CAN-intrusion dataset), just change the dataset name and follow the same steps. The models in this code are generic models that can be used in any intrusion detection/network traffic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/CICIDS2017_sample_km.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corresponding Attack Types:**  \n",
    "0 BENIGN &emsp; 18225  \n",
    "3 DoS        &emsp;   &emsp;   3042  \n",
    "6 WebAttack    &emsp;      2180  \n",
    "1 Bot        &emsp;  &emsp;      1966    \n",
    "5 PortScan  &emsp;       1255  \n",
    "2 BruteForce  &emsp;      96  \n",
    "4 Infiltration  &emsp;       36  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'],axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0) #shuffle=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SMOTE to solve class-imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1,sampling_strategy={2:1000,4:1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (ML) model training\n",
    "### Training three base learners: LightGBM, XGBoost, CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the LightGBM algorithm\n",
    "import lightgbm as lgb\n",
    "lg = lgb.LGBMClassifier()\n",
    "lg.fit(X_train, y_train)\n",
    "y_pred = lg.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy of LightGBM: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision of LightGBM: \"+ str(precision_score(y_test, y_pred, average='weighted')))\n",
    "print(\"Recall of LightGBM: \"+ str(recall_score(y_test, y_pred, average='weighted')))\n",
    "print(\"Average F1 of LightGBM: \"+ str(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(\"F1 of LightGBM for each type of attack: \"+ str(f1_score(y_test, y_pred, average=None)))\n",
    "lg_f1=f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the XGBoost algorithm\n",
    "import xgboost as xgb\n",
    "xg = xgb.XGBClassifier()\n",
    "\n",
    "X_train_x = X_train.values\n",
    "X_test_x = X_test.values\n",
    "\n",
    "xg.fit(X_train_x, y_train)\n",
    "\n",
    "y_pred = xg.predict(X_test_x)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy of XGBoost: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision of XGBoost: \"+ str(precision_score(y_test, y_pred, average='weighted')))\n",
    "print(\"Recall of XGBoost: \"+ str(recall_score(y_test, y_pred, average='weighted')))\n",
    "print(\"Average F1 of XGBoost: \"+ str(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(\"F1 of XGBoost for each type of attack: \"+ str(f1_score(y_test, y_pred, average=None)))\n",
    "xg_f1=f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the CatBoost algorithm\n",
    "import catboost as cbt\n",
    "cb = cbt.CatBoostClassifier(verbose=0,boosting_type='Plain')\n",
    "#cb = cbt.CatBoostClassifier()\n",
    "\n",
    "cb.fit(X_train, y_train)\n",
    "y_pred = cb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy of CatBoost: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision of CatBoost: \"+ str(precision_score(y_test, y_pred, average='weighted')))\n",
    "print(\"Recall of CatBoost: \"+ str(recall_score(y_test, y_pred, average='weighted')))\n",
    "print(\"Average F1 of CatBoost: \"+ str(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(\"F1 of CatBoost for each type of attack: \"+ str(f1_score(y_test, y_pred, average=None)))\n",
    "cb_f1=f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed ensemble model: Leader Class and Confidence Decision Ensemble (LCCDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCCDE aims to achieve optimal model performance by identifying the best-performing base ML model with the highest prediction confidence for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best-performing (leading) model for each type of attack among the three ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leading model list for each class\n",
    "model=[]\n",
    "for i in range(len(lg_f1)):\n",
    "    if max(lg_f1[i],xg_f1[i],cb_f1[i]) == lg_f1[i]:\n",
    "        model.append(lg)\n",
    "    elif max(lg_f1[i],xg_f1[i],cb_f1[i]) == xg_f1[i]:\n",
    "        model.append(xg)\n",
    "    else:\n",
    "        model.append(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "               objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "               reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "               objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "               reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None),\n",
       " LGBMClassifier(),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "               objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "               reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None),\n",
       " LGBMClassifier(),\n",
       " LGBMClassifier(),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "               objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "               reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leading Model for Each Type of Attack:**  \n",
    "0 BENIGN: &emsp; XGBClassifier  \n",
    "1 Bot:        &emsp;  &emsp;      XGBClassifier   \n",
    "2 BruteForce:  &emsp;      LGBMClassifier  \n",
    "3 DoS:        &emsp;   &emsp;   XGBClassifier  \n",
    "4 Infiltration:  &emsp;       LGBMClassifier  \n",
    "5 PortScan:  &emsp;       LGBMClassifier  \n",
    "6 WebAttack:    &emsp;      XGBClassifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LCCDE Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCCDE(X_test, y_test, m1, m2, m3):\n",
    "    i = 0\n",
    "    t = []\n",
    "    m = []\n",
    "    yt = []\n",
    "    yp = []\n",
    "    l = []\n",
    "    pred_l = []\n",
    "    pro_l = []\n",
    "\n",
    "    # For each class (normal or a type of attack), find the leader model\n",
    "    for xi, yi in stream.iter_pandas(X_test, y_test):\n",
    "\n",
    "        xi2=np.array(list(xi.values()))\n",
    "        y_pred1 = m1.predict(xi2.reshape(1, -1))      # model 1 (LightGBM) makes a prediction on text sample xi\n",
    "        y_pred1 = int(y_pred1[0])\n",
    "        y_pred2 = m2.predict(xi2.reshape(1, -1))      # model 2 (XGBoost) makes a prediction on text sample xi\n",
    "        y_pred2 = int(y_pred2[0])\n",
    "        y_pred3 = m3.predict(xi2.reshape(1, -1))      # model 3 (Catboost) makes a prediction on text sample xi\n",
    "        y_pred3 = int(y_pred3[0])\n",
    "\n",
    "        p1 = m1.predict_proba(xi2.reshape(1, -1))     # The prediction probability (confidence) list of model 1 \n",
    "        p2 = m2.predict_proba(xi2.reshape(1, -1))     # The prediction probability (confidence) list of model 2  \n",
    "        p3 = m3.predict_proba(xi2.reshape(1, -1))     # The prediction probability (confidence) list of model 3  \n",
    "\n",
    "        # Find the highest prediction probability among all classes for each ML model\n",
    "        y_pred_p1 = np.max(p1)\n",
    "        y_pred_p2 = np.max(p2)\n",
    "        y_pred_p3 = np.max(p3)\n",
    "\n",
    "        if y_pred1 == y_pred2 == y_pred3: # If the predicted classes of all the three models are the same\n",
    "            y_pred = y_pred1 # Use this predicted class as the final predicted class\n",
    "\n",
    "        elif y_pred1 != y_pred2 != y_pred3: # If the predicted classes of all the three models are different\n",
    "            # For each prediction model, check if the predicted classâ€™s original ML model is the same as its leader model\n",
    "            if model[y_pred1]==m1: # If they are the same and the leading model is model 1 (LightGBM)\n",
    "                l.append(m1)\n",
    "                pred_l.append(y_pred1) # Save the predicted class\n",
    "                pro_l.append(y_pred_p1) # Save the confidence\n",
    "\n",
    "            if model[y_pred2]==m2: # If they are the same and the leading model is model 2 (XGBoost)\n",
    "                l.append(m2)\n",
    "                pred_l.append(y_pred2)\n",
    "                pro_l.append(y_pred_p2)\n",
    "\n",
    "            if model[y_pred3]==m3: # If they are the same and the leading model is model 3 (CatBoost)\n",
    "                l.append(m3)\n",
    "                pred_l.append(y_pred3)\n",
    "                pro_l.append(y_pred_p3)\n",
    "\n",
    "            if len(l)==0: # Avoid empty probability list\n",
    "                pro_l=[y_pred_p1,y_pred_p2,y_pred_p3]\n",
    "\n",
    "            elif len(l)==1: # If only one pair of the original model and the leader model for each predicted class is the same\n",
    "                y_pred=pred_l[0] # Use the predicted class of the leader model as the final prediction class\n",
    "\n",
    "            else: # If no pair or multiple pairs of the original prediction model and the leader model for each predicted class are the same\n",
    "                max_p = max(pro_l) # Find the highest confidence\n",
    "                \n",
    "                # Use the predicted class with the highest confidence as the final prediction class\n",
    "                if max_p == y_pred_p1:\n",
    "                    y_pred = y_pred1\n",
    "                elif max_p == y_pred_p2:\n",
    "                    y_pred = y_pred2\n",
    "                else:\n",
    "                    y_pred = y_pred3  \n",
    "        \n",
    "        else: # If two predicted classes are the same and the other one is different\n",
    "            n = mode([y_pred1,y_pred2,y_pred3]) # Find the predicted class with the majority vote\n",
    "            y_pred = model[n].predict(xi2.reshape(1, -1)) # Use the predicted class of the leader model as the final prediction class\n",
    "            y_pred = int(y_pred[0]) \n",
    "\n",
    "        yt.append(yi)\n",
    "        yp.append(y_pred) # Save the predicted classes for all tested samples\n",
    "    return yt, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Implementing LCCDE\n",
    "yt, yp = LCCDE(X_test, y_test, m1 = lg, m2 = xg, m3 = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LCCDE: 0.9975746268656717\n",
      "Precision of LCCDE: 0.9975807247413017\n",
      "Recall of LCCDE: 0.9975746268656717\n",
      "Average F1 of LCCDE: 0.9975482770384609\n",
      "F1 of LCCDE for each type of attack: [0.99836021 0.99351492 1.         0.99836334 0.85714286 0.99137931\n",
      " 0.99889258]\n"
     ]
    }
   ],
   "source": [
    "# The performance of the proposed lCCDE model\n",
    "print(\"Accuracy of LCCDE: \"+ str(accuracy_score(yt, yp)))\n",
    "print(\"Precision of LCCDE: \"+ str(precision_score(yt, yp, average='weighted')))\n",
    "print(\"Recall of LCCDE: \"+ str(recall_score(yt, yp, average='weighted')))\n",
    "print(\"Average F1 of LCCDE: \"+ str(f1_score(yt, yp, average='weighted')))\n",
    "print(\"F1 of LCCDE for each type of attack: \"+ str(f1_score(yt, yp, average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of LightGBM for each type of attack: [0.99795054 0.99092088 1.         0.997543   0.85714286 0.99354839\n",
      " 0.99778271]\n",
      "F1 of XGBoost for each type of attack: [0.99836021 0.99351492 1.         0.99836334 0.85714286 0.99137931\n",
      " 0.99889258]\n",
      "F1 of CatBoost for each type of attack: [0.99781241 0.99222798 1.         0.99591837 0.85714286 0.99137931\n",
      " 0.9944629 ]\n"
     ]
    }
   ],
   "source": [
    "# Comparison: The F1-scores for each base model\n",
    "print(\"F1 of LightGBM for each type of attack: \"+ str(lg_f1))\n",
    "print(\"F1 of XGBoost for each type of attack: \"+ str(xg_f1))\n",
    "print(\"F1 of CatBoost for each type of attack: \"+ str(cb_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion**: The performance (F1-score) of the proposed LCCDE ensemble model on each type of attack detection is higher than any base ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
